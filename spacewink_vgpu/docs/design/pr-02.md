# Design Note: PR-02 - Native Kernel Scaffolding

**PR:** PR-02  
**Title:** Native Kernel Scaffolding (pybind11) + Basic MatMul  
**Date:** 2025-11-10  
**Author:** Autonomous Agent

---

## Overview

This PR establishes the foundational C++ kernel infrastructure with Python bindings using pybind11, and implements a basic, correct matrix multiplication kernel as proof-of-concept.

## Objectives

1. Set up pybind11 integration in the build system
2. Create C++ kernel module structure
3. Implement naive triple-loop matrix multiplication (correctness-focused)
4. Establish Python binding patterns
5. Create comprehensive unit tests
6. Record baseline performance metrics

## Algorithm: Basic Matrix Multiplication

### Approach
Naive triple-loop implementation:
```
C[i,j] = Σ(k=0 to K-1) A[i,k] * B[k,j]
```

### Complexity
- **Time:** O(M × N × K)
- **Space:** O(1) auxiliary
- **Memory Access:** Sequential for A rows, strided for B columns (cache-unfriendly)

### Expected Behavior
- **IO:** Read M×K + K×N floats, write M×N floats
- **Memory:** ~4 bytes × (M×K + K×N + M×N) for float32
- **Cache:** Poor locality for B matrix (column access)

## Implementation Structure

### C++ Files

**matmul_basic.h**
- Function declarations
- Type definitions
- Documentation

**matmul_basic.cpp**
- Naive triple-loop implementation
- Input validation
- Error handling

**kernels_bind.cpp**
- pybind11 module definition
- Function bindings with NumPy array interface
- Memory buffer management

### Python Files

**vgpu_runtime.py**
- High-level API wrapping C++ kernels
- NumPy array handling
- Type checking and validation

## Tests

### Unit Tests (test_matmul_basic.py)

1. **test_correctness_small** - 10×10 matrices vs NumPy
2. **test_correctness_medium** - 100×200×150 vs NumPy
3. **test_correctness_large** - 1000×500×800 vs NumPy
4. **test_edge_case_square** - Square matrices
5. **test_edge_case_tall** - M >> N
6. **test_edge_case_wide** - N >> M
7. **test_type_float32** - Explicit float32 handling
8. **test_benchmark_baseline** - Record timing for future comparison

### Integration Tests

1. **Memory leak check** - Valgrind integration
2. **Performance baseline** - Establish GFLOPS metric

## Performance Expectations

### Target Hardware Assumptions
- Intel/AMD x64 CPU, 2+ cores
- L1: 32 KB, L2: 256 KB, L3: 8 MB (typical)
- DRAM bandwidth: ~20 GB/s

### Naive Implementation Expected Performance
- **Small (100×100):** ~10-50 MFLOPS (cache-resident)
- **Medium (1000×1000):** ~50-200 MFLOPS (L3-resident)
- **Large (5000×5000):** ~100-500 MFLOPS (DRAM-bound)

Note: These are intentionally low - PR-03 will implement blocking to improve by 5-10x.

## Build Integration

### CMakeLists.txt Updates
```cmake
# Find pybind11
find_package(pybind11 CONFIG REQUIRED)

# Create kernel library
add_library(vgpu_kernels STATIC
    src/cpp/kernels/matmul_basic.cpp
)

# Create Python extension module
pybind11_add_module(_vgpu_kernels
    src/bindings/kernels_bind.cpp
)
target_link_libraries(_vgpu_kernels PRIVATE vgpu_kernels)
```

### setup.py Updates
- Add extension module configuration
- Ensure pybind11 is in build requirements

## Testing Strategy

### Correctness Validation
- Compare against NumPy with rtol=1e-6, atol=1e-6
- Test multiple sizes and aspect ratios
- Verify numerical stability

### Memory Safety
- Run Valgrind to detect leaks
- Check for buffer overflows
- Verify proper NumPy refcounting

### Performance Baseline
- Measure GFLOPS for reference
- Record timing for regression detection
- Profile with `perf stat`

## Acceptance Criteria

✅ pybind11 integration compiles successfully  
✅ Basic matmul produces correct results (matches NumPy)  
✅ All unit tests pass (8 tests minimum)  
✅ No memory leaks detected  
✅ Performance baseline recorded in artifacts  
✅ Documentation updated  
✅ CMake build integrates cleanly  

## Rollback Plan

1. Remove C++ kernel files
2. Remove binding files
3. Restore vgpu_runtime.py to stub
4. Remove CMake kernel sections
5. Verify build still succeeds

## Artifacts Generated

- `artifacts/pr-02/matmul_benchmark_baseline.json` - Performance metrics
- `artifacts/pr-02/valgrind_report.txt` - Memory safety report
- `artifacts/pr-02/correctness_tests.log` - Test outputs
- `artifacts/pr-02/build_log.txt` - Compilation log

## Next Steps (PR-03)

After this PR:
- Implement blocked/tiled GEMM
- Add AVX2 vectorization
- Create autotuner for tile size selection
- Target 5-10x performance improvement

---

**Status:** Ready for implementation  
**Estimated Effort:** 3-4 days  
**Risk Level:** Low
