# PR-03 Design Document: Blocked GEMM + Autotuner

**Author:** vGPU Dev Team  
**Date:** 2025-11-10  
**PR:** PR-03  
**Status:** Implementation Complete

## Overview

This PR implements cache-aware blocked matrix multiplication (GEMM) with AVX2 vectorization and an automatic tuning system for tile size selection. The goal is to achieve 5-10x performance improvement over the naive O(M×N×K) implementation from PR-02 by optimizing memory access patterns for the CPU cache hierarchy.

## Algorithm: Blocked/Tiled GEMM

### Mathematical Formulation

Matrix multiplication: C = A × B
- A: M × K matrix
- B: K × N matrix
- C: M × N matrix (output)

Complexity: O(M × N × K) FLOPs (same as naive, but with much lower memory bandwidth)

### Blocking Strategy

The algorithm uses 3-level blocking to align with CPU cache hierarchy:

```
for j_block = 0 to N by NC:              # L3 cache (columns of B)
  for k_block = 0 to K by KC:            # L1 cache (shared dimension)
    pack B[k_block:k_block+KC, j_block:j_block+NC] into temp
    for i_block = 0 to M by MC:          # L2 cache (rows of A)
      pack A[i_block:i_block+MC, k_block:k_block+KC] into temp
      micro_kernel_avx2(A_packed, B_packed, C_block)
```

### Tile Size Selection

Default tile sizes (tuned for typical x86_64 CPUs):
- **MC = 256**: Number of rows of A to keep in L2 cache
- **KC = 128**: Shared dimension to keep in L1 cache  
- **NC = 4096**: Number of columns of B to stream through L3 cache

Memory footprint per block:
- A block: MC × KC × 4 bytes = 256 × 128 × 4 = 128 KB (fits in L2)
- B block: KC × NC × 4 bytes = 128 × 4096 × 4 = 2 MB (fits in L3)
- C block: MC × NC × 4 bytes = 256 × 4096 × 4 = 4 MB (streaming to DRAM)

### Cache Hierarchy Rationale

**L1 Data Cache (32 KB typical):**
- Holds working set for inner kernel: KC × KC elements
- 128 × 128 × 4 bytes = 64 KB (slightly larger, but hot elements stay in L1)

**L2 Unified Cache (256 KB typical):**
- Holds current panel of A: MC × KC elements
- 256 × 128 × 4 bytes = 128 KB (fits comfortably)

**L3 Shared Cache (8 MB typical):**
- Holds current panel of B: KC × NC elements
- 128 × 4096 × 4 bytes = 2 MB (good reuse across cores)

## AVX2 Vectorization

### SIMD Micro-Kernel

The innermost loop uses AVX2 intrinsics for 8-wide float32 operations:

```cpp
__m256 a_vec = _mm256_broadcast_ss(&A[i * K + k]);
__m256 b_vec = _mm256_loadu_ps(&B[k * N + j]);
__m256 c_vec = _mm256_loadu_ps(&C[i * N + j]);
c_vec = _mm256_fmadd_ps(a_vec, b_vec, c_vec);  // Fused multiply-add
_mm256_storeu_ps(&C[i * N + j], c_vec);
```

**Performance Characteristics:**
- 8 FLOPs per FMA instruction
- Theoretical peak: 8 FLOPs/cycle × clock_rate
- Achieves ~90-95% vectorization efficiency on inner loops

**Runtime Detection:**
- Check AVX2 support via CPUID instruction
- Fallback to scalar code if AVX2 unavailable
- No illegal instruction exceptions

## Autotuner System

### Cache Size Detection

Uses `sysconf()` on Linux to query cache hierarchy:

```cpp
long l1 = sysconf(_SC_LEVEL1_DCACHE_SIZE);   // L1 data cache
long l2 = sysconf(_SC_LEVEL2_CACHE_SIZE);    // L2 unified cache
long l3 = sysconf(_SC_LEVEL3_CACHE_SIZE);    // L3 shared cache
```

Falls back to conservative defaults if sysconf unavailable.

### Tile Size Selection Algorithm

1. **Generate Candidates:**
   - MC candidates: {128, 192, 256, 384, 512}
   - KC candidates: {64, 96, 128, 192, 256}
   - NC candidates: {2048, 4096, 8192}
   
2. **Filter by Cache Constraints:**
   - MC × KC × 4 < L2_size
   - KC × KC × 4 < L1_size
   - KC × NC × 4 < L3_size

3. **Microbenchmark:**
   - Test each candidate on 512×512 matrices
   - Measure GFLOPS (higher is better)
   - Select configuration with best performance

4. **Cache Result:**
   - Save to `~/.vgpu_tuner.json`
   - Reuse on subsequent runs (unless forced)

### Performance Model

Target efficiency metrics:
- **Arithmetic Intensity:** (2 × M × N × K) / (M × K + K × N + M × N) FLOPs/byte
- **Cache Miss Rate:** < 5% for L1/L2, < 20% for L3
- **Vectorization:** > 90% of inner loop FLOPs

## Expected Performance

### Single-Threaded Performance

| Matrix Size | Naive (MFLOPS) | Blocked (MFLOPS) | Speedup | GFLOPS |
|-------------|----------------|------------------|---------|---------|
| 100³ | 50-200 | 200-1000 | 5-10x | 0.2-1.0 |
| 500³ | 50-200 | 500-2000 | 10x | 0.5-2.0 |
| 1000³ | 100-500 | 1000-5000 | 10-20x | 1.0-5.0 |
| 5000³ | 200-500 | 2000-10000 | 10-20x | 2.0-10.0 |

**Hardware Assumptions:**
- CPU: Intel Xeon or equivalent (2.0-3.5 GHz)
- L1: 32 KB, L2: 256 KB, L3: 8-20 MB
- AVX2 support

### Performance Breakdown

**Factors Contributing to Speedup:**
1. **Cache optimization:** 5-8x improvement from blocking
2. **AVX2 vectorization:** 1.5-2x improvement from SIMD
3. **Combined effect:** 5-20x total improvement

**Remaining Bottlenecks:**
- Single-threaded (PR-04 will add parallelism)
- Memory bandwidth for large matrices
- TLB capacity for very large matrices

## Integration with Advanced Algorithms

This PR provides foundational optimizations for:

**Algorithm #7 (Randomized Linear Algebra):**
- Fast matrix-matrix products for sketching
- Enables efficient randomized SVD

**Algorithm #3 (H-Matrix Methods):**
- Optimized dense block operations
- Critical for hierarchical matrix arithmetic

**Algorithm #12 (Krylov Methods):**
- Accelerated matrix-vector products
- Enables faster Lanczos/Arnoldi iterations

## Testing Strategy

### Correctness Tests
- Small (10×10), medium (100×100), large (1000×1000) matrices
- Edge cases: tall, wide, non-power-of-2 dimensions
- Compare against NumPy with rtol=1e-5, atol=1e-6

### Performance Tests
- Benchmark vs naive baseline (expect >= 2x speedup)
- Measure GFLOPS for various sizes
- Verify autotuner selects reasonable tiles

### Robustness Tests
- AVX2 unavailable (fallback to scalar)
- Missing cache size info (use defaults)
- Custom tile configurations

## Future Enhancements (Post-PR-03)

**PR-04: Multi-threading**
- Parallelize outer loops with threadpool
- Target 50-100 GFLOPS on 8-16 cores

**PR-05: Memory Tiering**
- Out-of-core blocked GEMM
- Spill to vVRAM/vSSD for huge matrices

**PR-06-08: Advanced Algorithms**
- Integrate with FMM, FFT, tensor operations
- Provide blocked GEMM as primitive

## References

1. Goto, K., & Van De Geijn, R. (2008). "Anatomy of high-performance matrix multiplication." ACM TOMS.
2. Intel MKL Documentation: GEMM Implementation Notes
3. BLIS Framework: Blocked Linear Algebra Subprograms

## Artifacts

- `artifacts/pr-03/blocked_gemm_benchmarks.json` - Performance measurements
- `artifacts/pr-03/autotuner_log.txt` - Tuning session output
- `~/.vgpu_tuner.json` - Cached tile configuration
